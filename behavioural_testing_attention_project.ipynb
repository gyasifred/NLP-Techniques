{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/NLP-Techniques/blob/main/behavioural_testing_attention_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPnOmSAU4zzE",
        "outputId": "04c138f8-8b0e-4b2a-c667-97d15300b1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeOBjCJg-ceH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Tuple, Dict\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(train_path: str, test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame, LabelEncoder]:\n",
        "    \"\"\"\n",
        "    Load and preprocess the training and testing data.\n",
        "\n",
        "    This function reads training and testing datasets from CSV files, checks for the required columns,\n",
        "    encodes the target variable using LabelEncoder, and returns the processed DataFrames along with\n",
        "    the fitted LabelEncoder.\n",
        "\n",
        "    Args:\n",
        "        train_path (str): The file path for the training data CSV.\n",
        "        test_path (str): The file path for the testing data CSV.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame, LabelEncoder]: A tuple containing:\n",
        "            - train_df (pd.DataFrame): The preprocessed training DataFrame with encoded 'prognosis'.\n",
        "            - test_df (pd.DataFrame): The preprocessed testing DataFrame with encoded 'prognosis'.\n",
        "            - label_encoder (LabelEncoder): The fitted LabelEncoder used for encoding the 'prognosis' labels.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified files do not exist.\n",
        "        ValueError: If the necessary columns ('prognosis', 'symptoms') are missing from the datasets.\n",
        "        pd.errors.EmptyDataError: If the CSV files are empty.\n",
        "        Exception: For any other unforeseen errors that may occur during execution.\n",
        "\n",
        "    Example:\n",
        "        >>> train_df, test_df, encoder = load_and_preprocess_data(\"train.csv\", \"test.csv\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the data\n",
        "        train_df = pd.read_csv(train_path)\n",
        "        test_df = pd.read_csv(test_path)\n",
        "\n",
        "        # Check if necessary columns exist\n",
        "        if 'prognosis' not in train_df.columns or 'prognosis' not in test_df.columns:\n",
        "            raise ValueError(\"The 'prognosis' column is missing from the datasets.\")\n",
        "        if 'symptoms' not in train_df.columns or 'symptoms' not in test_df.columns:\n",
        "            raise ValueError(\"The 'symptoms' column is missing from the datasets.\")\n",
        "\n",
        "        # Initialize and fit the LabelEncoder\n",
        "        label_encoder = LabelEncoder()\n",
        "        train_df['prognosis'] = label_encoder.fit_transform(train_df['prognosis'])\n",
        "        test_df['prognosis'] = label_encoder.transform(test_df['prognosis'])\n",
        "\n",
        "        return train_df, test_df, label_encoder\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"Error: The file is empty.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "meTo_tC1CtCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "train_df, test_df, label_encoder = load_and_preprocess_data(\"/content/drive/MyDrive/Training.csv\",\n",
        "                                                            \"/content/drive/MyDrive/Testing.csv\")"
      ],
      "metadata": {
        "id": "f6hzks-QCxYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqVCiSHKC1ve",
        "outputId": "54cc086a-ce41-428d-e1f3-deb3c9f80ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/MT/trained_biobert_tokenizer\")\n",
        "# model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/MT/trained_biobert_model\",\n",
        "#                                                       attn_implementation='eager',\n",
        "#                                                       num_labels=num_classes, output_attentions=True)\n",
        "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "# model.to(device)\n",
        "\n",
        "# Specify the model name for BioBERT\n",
        "MODEL_NAME = \"dmis-lab/biobert-v1.1\"\n",
        "\n",
        "# Load the tokenizer for the specified BioBERT model\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load the pre-trained BioBERT model for sequence classification\n",
        "# - attn_implementation='eager': Specifies the attention implementation mode.\n",
        "# - eager implementation is default in pytorch\n",
        "# - num_labels=num_classes: Sets the number of labels for classification.\n",
        "# - output_attentions=True: Enables the model to output attention weights.\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, attn_implementation='eager', num_labels=num_classes, output_attentions=True)\n",
        "\n",
        "# Set the device to GPU if available, otherwise fallback to CPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move the model to the specified device for computation\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsjetF6EC5Me",
        "outputId": "57c24ea3-0162-438a-831d-79e8c1bc45df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=41, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom Dataset class to handle text data for training/testing with a transformer model.\n",
        "    Each sample consists of tokenized input (symptoms) and corresponding labels (prognosis).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, tokenizer: BertTokenizer, max_length: int):\n",
        "        \"\"\"\n",
        "        Initializes the dataset with a DataFrame, tokenizer, and maximum tokenized sequence length.\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): A pandas DataFrame containing 'symptoms' (text input) and 'prognosis' (labels).\n",
        "            tokenizer (BertTokenizer): Pre-trained tokenizer (e.g., from the BERT model) for text tokenization.\n",
        "            max_length (int): Maximum length for tokenized input sequences. Longer sequences will be truncated,\n",
        "                              and shorter ones will be padded.\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = dataframe['symptoms'].astype(str).tolist()  # Convert symptoms column to list of strings\n",
        "        self.labels = dataframe['prognosis'].values  # Store prognosis (labels) as numpy array\n",
        "        self.max_length = max_length  # Maximum sequence length for tokenization\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Generates a single sample of data. Each sample consists of the tokenized text\n",
        "        (input_ids, attention_mask) and its corresponding label.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, torch.Tensor]: A dictionary containing:\n",
        "                - 'input_ids': Tensor of tokenized input IDs.\n",
        "                - 'attention_mask': Tensor indicating which tokens are padding.\n",
        "                - 'labels': Tensor of the corresponding label for classification.\n",
        "        \"\"\"\n",
        "        # Get the text and label at the specified index\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Tokenize the text input\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,  # Add special tokens like [CLS] and [SEP]\n",
        "            max_length=self.max_length,  # Truncate sequences longer than max_length\n",
        "            padding='max_length',  # Pad shorter sequences to max_length\n",
        "            truncation=True,  # Truncate longer sequences to fit within max_length\n",
        "            return_tensors=\"pt\"  # Return the tokenized output as PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # Return the tokenized input IDs, attention mask, and label as a dictionary\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),  # Remove extra batch dimension\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),  # Remove extra batch dimension\n",
        "            'labels': torch.tensor(label, dtype=torch.long)  # Convert the label to a tensor\n",
        "        }"
      ],
      "metadata": {
        "id": "frGMdNvTC9FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(train_df: pd.DataFrame, test_df: pd.DataFrame,\n",
        "                         tokenizer: BertTokenizer, batch_size: int = 16) -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Create DataLoaders for the training and testing datasets, which will be used\n",
        "    to feed tokenized inputs into the model in batches.\n",
        "\n",
        "    Args:\n",
        "        train_df (pd.DataFrame): A pandas DataFrame containing the training data.\n",
        "        test_df (pd.DataFrame): A pandas DataFrame containing the testing data.\n",
        "        tokenizer (BertTokenizer): Pre-trained tokenizer to tokenize the input text.\n",
        "        batch_size (int): Number of samples per batch for the DataLoader. Default is 16.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[DataLoader, DataLoader]: Returns two DataLoader objects:\n",
        "            - train_loader: DataLoader for the training dataset.\n",
        "            - test_loader: DataLoader for the testing dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Instantiate the custom dataset for training using the training DataFrame\n",
        "    # This assumes that the CustomTextDataset class is defined elsewhere and handles tokenization\n",
        "    train_dataset = CustomTextDataset(train_df, tokenizer, max_length=512)\n",
        "\n",
        "    # Instantiate the custom dataset for testing using the testing DataFrame\n",
        "    test_dataset = CustomTextDataset(test_df, tokenizer, max_length=512)\n",
        "\n",
        "    # Create the DataLoader for training with shuffling (randomizes data order during training)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Create the DataLoader for testing without shuffling (we typically don't shuffle test data)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Return both DataLoaders\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "YZmw4pd-DGR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader, test_loader = create_data_loaders(train_df,\n",
        "                                                test_df, tokenizer)"
      ],
      "metadata": {
        "id": "P9mG_RlODJZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model: BertForSequenceClassification, train_loader: DataLoader, num_epochs: int = 3):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)  # Move to the same device as the model\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            try:\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error during forward pass: {e}\")\n",
        "                continue\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "R0CuG9d17U0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwJPMGsf777s",
        "outputId": "0c31a0f5-c2e1-4566-bdde-276181e8c01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 2.3498\n",
            "Epoch 2/3, Loss: 0.4692\n",
            "Epoch 3/3, Loss: 0.1546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the paths for saving the model and tokenizer\n",
        "model_save_path = \"/content/drive/MyDrive/MT/trained_biobert_model\"\n",
        "tokenizer_save_path = '/content/drive/MyDrive/MT/trained_biobert_tokenizer'\n",
        "\n",
        "# Saving the model and tokenizer\n",
        "model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(tokenizer_save_path)\n",
        "\n",
        "print(\"Model and tokenizer saved locally!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFq9pI2Y8ozG",
        "outputId": "97d655e1-4d33-40b4-aebc-1c56f6a318fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved locally!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model: BertForSequenceClassification, test_loader: DataLoader,\n",
        "                   label_encoder: LabelEncoder):\n",
        "    \"\"\"\n",
        "    Evaluate a pre-trained BERT model on a test dataset, and compute accuracy and classification metrics.\n",
        "\n",
        "    Args:\n",
        "    - model (BertForSequenceClassification): The fine-tuned BERT model for sequence classification.\n",
        "    - test_loader (DataLoader): DataLoader for the test set, containing batches of tokenized inputs.\n",
        "    - label_encoder (LabelEncoder): A label encoder used to decode numerical predictions back to their original labels.\n",
        "\n",
        "    Returns:\n",
        "    None. Prints the accuracy and classification report including precision, recall, and F1-score for each class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set model to evaluation mode (disables dropout, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store predictions and true labels\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Disable gradient calculations during evaluation for faster inference\n",
        "    with torch.no_grad():\n",
        "        # Loop through each batch of the test data\n",
        "        for batch in test_loader:\n",
        "            # Move the input tensors to the same device as the model (GPU or CPU)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass: get logits (raw prediction scores) from the model\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Get the predicted class by taking the index of the max logit value (highest score)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "            # Move predictions and true labels to CPU and convert to lists\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            true_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    # Calculate accuracy by comparing predictions with the true labels\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    # Generate a detailed classification report (precision, recall, F1-score) for each class\n",
        "    report = classification_report(true_labels, predictions,\n",
        "                                   target_names=label_encoder.classes_)\n",
        "\n",
        "    # Print out the evaluation results\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "nw5mFPEIDNd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "pprint(evaluate_model(model, test_loader, label_encoder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhWa4kTW8lKj",
        "outputId": "0d5a256e-4eb4-4769-a910-bca5c85ae8c0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "                                         precision    recall  f1-score   support\n",
            "\n",
            "(vertigo) Paroymsal  Positional Vertigo       1.00      1.00      1.00        25\n",
            "                                   AIDS       1.00      1.00      1.00        24\n",
            "                                   Acne       1.00      1.00      1.00        24\n",
            "                    Alcoholic hepatitis       1.00      1.00      1.00        25\n",
            "                                Allergy       1.00      1.00      1.00        24\n",
            "                              Arthritis       1.00      1.00      1.00        24\n",
            "                       Bronchial Asthma       1.00      1.00      1.00        25\n",
            "                   Cervical spondylosis       1.00      1.00      1.00        24\n",
            "                            Chicken pox       1.00      1.00      1.00        24\n",
            "                    Chronic cholestasis       1.00      1.00      1.00        25\n",
            "                            Common Cold       1.00      1.00      1.00        24\n",
            "                                 Dengue       1.00      1.00      1.00        24\n",
            "                              Diabetes        1.00      1.00      1.00        24\n",
            "           Dimorphic hemmorhoids(piles)       1.00      1.00      1.00        24\n",
            "                          Drug Reaction       1.00      1.00      1.00        24\n",
            "                       Fungal infection       1.00      1.00      1.00        25\n",
            "                                   GERD       1.00      1.00      1.00        24\n",
            "                        Gastroenteritis       1.00      1.00      1.00        24\n",
            "                           Heart attack       1.00      1.00      1.00        24\n",
            "                            Hepatitis B       1.00      1.00      1.00        24\n",
            "                            Hepatitis C       1.00      1.00      1.00        25\n",
            "                            Hepatitis D       1.00      1.00      1.00        24\n",
            "                            Hepatitis E       1.00      1.00      1.00        25\n",
            "                          Hypertension        1.00      1.00      1.00        24\n",
            "                        Hyperthyroidism       1.00      1.00      1.00        25\n",
            "                           Hypoglycemia       1.00      1.00      1.00        24\n",
            "                         Hypothyroidism       1.00      1.00      1.00        24\n",
            "                               Impetigo       1.00      1.00      1.00        24\n",
            "                               Jaundice       1.00      1.00      1.00        24\n",
            "                                Malaria       1.00      1.00      1.00        24\n",
            "                               Migraine       1.00      1.00      1.00        24\n",
            "                        Osteoarthristis       1.00      1.00      1.00        24\n",
            "           Paralysis (brain hemorrhage)       1.00      1.00      1.00        24\n",
            "                    Peptic ulcer diseae       1.00      1.00      1.00        24\n",
            "                              Pneumonia       1.00      1.00      1.00        24\n",
            "                              Psoriasis       1.00      1.00      1.00        24\n",
            "                           Tuberculosis       1.00      1.00      1.00        24\n",
            "                                Typhoid       1.00      1.00      1.00        24\n",
            "                Urinary tract infection       1.00      1.00      1.00        24\n",
            "                         Varicose veins       1.00      1.00      1.00        25\n",
            "                            hepatitis A       1.00      1.00      1.00        24\n",
            "\n",
            "                               accuracy                           1.00       993\n",
            "                              macro avg       1.00      1.00      1.00       993\n",
            "                           weighted avg       1.00      1.00      1.00       993\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attention_weights(text: str, model: BertForSequenceClassification,\n",
        "                          tokenizer: BertTokenizer, label_encoder: LabelEncoder,\n",
        "                          layer_num: int = -1, head_num: int = -1):\n",
        "    \"\"\"\n",
        "    Extracts attention weights from a BERT model for a given input text.\n",
        "\n",
        "    This function tokenizes the input text, performs a forward pass through\n",
        "    the BERT model to obtain attention weights from a specified layer and head,\n",
        "    and aggregates attention weights for tokens and their corresponding words.\n",
        "    Additionally, it returns the logits of the model output.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text for which to extract attention weights.\n",
        "        model (BertForSequenceClassification): The BERT model to use for predictions.\n",
        "        tokenizer (BertTokenizer): The tokenizer corresponding to the BERT model.\n",
        "        label_encoder (LabelEncoder): The label encoder for inverse transforming class labels.\n",
        "        layer_num (int, optional): The layer number from which to extract attention weights.\n",
        "                                    Default is -1 (last layer).\n",
        "        head_num (int, optional): The head number from which to extract attention weights.\n",
        "                                   Default is -1 (last head).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[float], List[str], torch.Tensor]: A tuple containing:\n",
        "            - A list of attention weights for each word.\n",
        "            - A list of words corresponding to the attention weights.\n",
        "            - The logits of the model's output.\n",
        "    \"\"\"\n",
        "    # Set the device to match the model's device (GPU/CPU)\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Tokenize the input text and convert it to tensor format for model input\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True,\n",
        "                       truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Set model to evaluation mode and disable gradient calculation for inference\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through the model to get outputs, including attention weights\n",
        "        outputs = model(**inputs, output_attentions=True)\n",
        "\n",
        "    # Extract the attention weights from the specified layer and head\n",
        "    # outputs.attentions has shape (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
        "    attentions = outputs.attentions[layer_num][0][head_num].detach().cpu().numpy()\n",
        "\n",
        "    # Get the attention of the [CLS] token (index 0) to other tokens, excluding special tokens\n",
        "    cls_attention = attentions[0, :][1:-1]\n",
        "\n",
        "    # Convert token IDs back to readable words, excluding [CLS] and [SEP] tokens\n",
        "    words = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    words = words[1:-1]  # Exclude [CLS] (index 0) and [SEP] (last token)\n",
        "\n",
        "    # Initialize a list to hold words and their corresponding attention weights\n",
        "    final_attention_weights = []\n",
        "    input_words = []\n",
        "\n",
        "    # Initialize temporary variables for concatenating subwords\n",
        "    current_word = \"\"\n",
        "    current_attention_sum = 0.0\n",
        "\n",
        "    for i, token in enumerate(words):\n",
        "        # Check if the token is a subword\n",
        "        if token.startswith('##'):\n",
        "            # If it's a subword, concatenate it to the current word\n",
        "            current_word += token[2:]  # Remove '##' and append to current word\n",
        "            current_attention_sum += cls_attention[i]  # Sum the attention weight\n",
        "        else:\n",
        "            # If it's a new word and we have a current_word, save it to the list\n",
        "            if current_word:\n",
        "                final_attention_weights.append(current_attention_sum)\n",
        "                input_words.append(current_word)\n",
        "\n",
        "            # Start a new current word with the current token\n",
        "            current_word = token\n",
        "            current_attention_sum = cls_attention[i]  # Reset attention sum to current\n",
        "\n",
        "    # Don't forget to add the last word\n",
        "    if current_word:\n",
        "        final_attention_weights.append(current_attention_sum)\n",
        "        input_words.append(current_word)\n",
        "\n",
        "    return final_attention_weights, input_words, outputs.logits"
      ],
      "metadata": {
        "id": "yVwHd37u77fN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(text: str, model: BertForSequenceClassification,\n",
        "                   tokenizer: BertTokenizer, label_encoder: LabelEncoder,\n",
        "                   layer_num: int = -1, head_num: int = -1):\n",
        "    \"\"\"\n",
        "    Plot the attention weights for a given text input, specifically focusing on a\n",
        "    selected attention head and layer of the model. This function also shows the\n",
        "    predicted class for the input text.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The input text to analyze attention for.\n",
        "    - model (BertForSequenceClassification): Pre-trained BERT model for sequence classification.\n",
        "    - tokenizer (BertTokenizer): Tokenizer associated with the BERT model.\n",
        "    - label_encoder (LabelEncoder): Encoder to decode predicted labels.\n",
        "    - layer_num (int): The layer number to extract attention weights from. Defaults to -1 (last layer).\n",
        "    - head_num (int): The head number to extract attention weights from. Defaults to -1 (last head).\n",
        "\n",
        "    Returns:\n",
        "    None. Displays a bar chart showing the attention weights of the [CLS] token for each word in the input text.\n",
        "    \"\"\"\n",
        "\n",
        "    cls_attention, words, logits = get_attention_weights(text, model, tokenizer, label_encoder,\n",
        "                                                         layer_num, head_num)\n",
        "    # Calculate the model's prediction by getting the predicted class\n",
        "    probs = F.softmax(logits, dim=-1)  # Apply softmax to get class probabilities\n",
        "    predicted_class = probs.argmax(dim=-1).item()  # Get the class index with the highest probability\n",
        "    prediction = label_encoder.inverse_transform([predicted_class])[0]  # Decode class to label\n",
        "\n",
        "        # Create a plot to visualize attention weights for each token\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    fig.suptitle(f\"Attention Analysis (Layer: {layer_num}, Head: {head_num})\\nPrediction: {prediction}\",\n",
        "                  fontsize=16)\n",
        "\n",
        "    # Prepare data for the horizontal bar chart\n",
        "    y_pos = np.arange(len(words))\n",
        "    ax.barh(y_pos, cls_attention, align='center')  # Plot attention weights as bars\n",
        "\n",
        "    # Set labels and axis information\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(words)  # Set word labels on the y-axis\n",
        "    ax.invert_yaxis()  # Invert the y-axis to display tokens from top to bottom\n",
        "    ax.set_xlabel('Attention Weights')\n",
        "\n",
        "    # Ensure layout is adjusted properly\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print input text and the tokenized words for reference\n",
        "    print(f\"Input words: {' '.join(words)}\")"
      ],
      "metadata": {
        "id": "H4IFZrQfb-Vf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"58yo man presents with stomach pain and acute shortness of breath\""
      ],
      "metadata": {
        "id": "nCLHdJY1DV9F"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention(text, model, tokenizer,label_encoder, layer_num= -1, head_num= -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "gLndLkcwg6pV",
        "outputId": "b9f7f2f8-0ac5-4ed7-dd8f-1fc60e93d7eb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input words: 58yo man presents with stomach pain and acute shortness of breath\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_with_probabilities(\n",
        "    text: str,\n",
        "    model: BertForSequenceClassification,\n",
        "    tokenizer: BertTokenizer,\n",
        "    label_encoder: LabelEncoder\n",
        "):\n",
        "    \"\"\"\n",
        "    Get predicted labels and their probabilities for a given text input using a pre-trained BERT model.\n",
        "\n",
        "    This function tokenizes the input text, runs it through a BERT model for sequence classification,\n",
        "    and returns the predicted labels along with their respective probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    text : str\n",
        "        The input text for which predictions are to be made.\n",
        "\n",
        "    model : BertForSequenceClassification\n",
        "        The pre-trained BERT model for sequence classification. This model should be in evaluation mode.\n",
        "\n",
        "    tokenizer : BertTokenizer\n",
        "        The tokenizer corresponding to the pre-trained BERT model. It is used to convert input text into\n",
        "        tokens and further into input tensors for the model.\n",
        "\n",
        "    label_encoder : LabelEncoder\n",
        "        The label encoder used to transform label indices into human-readable labels.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple containing:\n",
        "        - labels : np.ndarray\n",
        "            The predicted labels corresponding to the input text. These are the inverse transformed labels from the label encoder.\n",
        "        - probs_np : np.ndarray\n",
        "            An array of probabilities associated with each label, representing the model's confidence in its predictions.\n",
        "\n",
        "    Notes:\n",
        "    -----\n",
        "    - The function uses PyTorch for model inference. Ensure that the model and tokenizer are loaded correctly\n",
        "      and that the appropriate device (CPU or GPU) is set prior to calling this function.\n",
        "    - The input text is truncated to a maximum length of 512 tokens as required by BERT.\n",
        "    - Softmax is applied to the logits obtained from the model to convert them into probabilities.\n",
        "    - The gradient calculation is disabled during inference to save memory and computation time.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    labels, probabilities = get_predictions_with_probabilities(\"Sample text for prediction.\", model, tokenizer, label_encoder)\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize the input text and convert it into PyTorch tensors\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True,\n",
        "                       truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        outputs = model(**inputs)  # Forward pass through the model\n",
        "\n",
        "    logits = outputs.logits  # Get the raw prediction scores (logits)\n",
        "\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Convert probabilities to numpy array for easier manipulation\n",
        "    probs_np = probs.cpu().numpy()[0]\n",
        "\n",
        "    # Get all labels based on the label encoder's mapping\n",
        "    labels = label_encoder.inverse_transform(range(len(probs_np)))\n",
        "\n",
        "    return labels, probs_np\n"
      ],
      "metadata": {
        "id": "kUX8Jjsmjst-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANSI escape codes for colors and formatting\n",
        "RESET = \"\\033[0m\"\n",
        "BOLD = \"\\033[1m\"\n",
        "LIGHT_GREEN = \"\\033[38;2;144;238;144m\"  # Light green for highlighting\n",
        "BG_PURPLE = \"\\033[45m\"  # Purple background for highlighting the max attention word and top prediction\n",
        "\n",
        "# Unicode subscript characters for digits 0-9\n",
        "subscript_digits = {\n",
        "    '0': '\\u2080',\n",
        "    '1': '\\u2081',\n",
        "    '2': '\\u2082',\n",
        "    '3': '\\u2083',\n",
        "    '4': '\\u2084',\n",
        "    '5': '\\u2085',\n",
        "    '6': '\\u2086',\n",
        "    '7': '\\u2087',\n",
        "    '8': '\\u2088',\n",
        "    '9': '\\u2089',\n",
        "}\n",
        "\n",
        "def to_subscript(num):\n",
        "    \"\"\"Convert a number to subscript format.\"\"\"\n",
        "    # First, round the number to two decimal places as a string\n",
        "    formatted_num = f\"{num:.5f}\"\n",
        "\n",
        "    # Then, convert the number to subscript format\n",
        "    return ''.join(subscript_digits.get(digit, digit) for digit in formatted_num)\n",
        "\n",
        "def generate_color(value, max_value):\n",
        "    \"\"\"Generate a color from red (low value) to green (high value).\"\"\"\n",
        "    r = int(255 * (1 - value / max_value))\n",
        "    g = int(255 * (value / max_value))\n",
        "    b = 0\n",
        "    return f\"\\033[38;2;{r};{g};{b}m\"\n",
        "\n",
        "def visualize_attention_and_predictions(\n",
        "    text: str,\n",
        "    model: BertForSequenceClassification,\n",
        "    tokenizer: BertTokenizer,\n",
        "    label_encoder: LabelEncoder,\n",
        "    layer_num: int = -1,\n",
        "    head_num: int = -1\n",
        "):\n",
        "    \"\"\"Visualize attention weights and predictions for a given text using a BERT model.\"\"\"\n",
        "\n",
        "    # Get prediction probabilities\n",
        "    labels, prediction_probs = get_predictions_with_probabilities(text, model, tokenizer, label_encoder)\n",
        "\n",
        "    # Get attention weights\n",
        "    cls_attention, words,_ = get_attention_weights(text, model, tokenizer, label_encoder, layer_num, head_num)\n",
        "\n",
        "    # Zip words with their corresponding attention weights\n",
        "    word_attention_pairs = list(zip(words, cls_attention))\n",
        "\n",
        "    # Sort predictions by probability\n",
        "    prediction_probability_pairs = list(zip(labels, prediction_probs))\n",
        "    prediction_probability_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Find max attention and max probability\n",
        "    max_attention = max(cls_attention)\n",
        "    max_probability = max(prediction_probs)\n",
        "    # Generate output for input words\n",
        "    print(BOLD + \"Input Words:\" + RESET)\n",
        "    for word, attn in word_attention_pairs:\n",
        "        color = generate_color(attn, max_attention)\n",
        "        background = BG_PURPLE if attn == max_attention else \"\"\n",
        "        print(f\"{background}{word}{RESET} {color}{to_subscript(attn)}{RESET}\", end=\" \")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Generate output for predictions\n",
        "    print(BOLD + \"Top Predictions:\" + RESET)\n",
        "    for i, (pred, prob) in enumerate(prediction_probability_pairs[:3]):\n",
        "        color = generate_color(prob, max_probability)\n",
        "        background = BG_PURPLE if i == 0 else \"\"  # Highlight the top prediction\n",
        "        print(f\"{background}{pred}{RESET} {color}{to_subscript(prob)}{RESET}\", end=\" \")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "w6S3FHdzl84Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text = \"58yo man presents with stomach pain and acute shortness of breath\"\n",
        "visualize_attention_and_predictions(text, model, tokenizer, label_encoder, layer_num=-1, head_num=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBH442e6pLo4",
        "outputId": "7da7a8bf-c230-4778-ed4f-966d229afe9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mInput Words:\u001b[0m\n",
            "\u001b[45m58yo\u001b[0m \u001b[38;2;0;255;0m₀.₂₄₁₉₄\u001b[0m man\u001b[0m \u001b[38;2;243;11;0m₀.₀₁₀₄₈\u001b[0m presents\u001b[0m \u001b[38;2;240;14;0m₀.₀₁₄₁₈\u001b[0m with\u001b[0m \u001b[38;2;251;3;0m₀.₀₀₃₆₃\u001b[0m stomach\u001b[0m \u001b[38;2;200;54;0m₀.₀₅₁₈₇\u001b[0m pain\u001b[0m \u001b[38;2;220;34;0m₀.₀₃₂₉₀\u001b[0m and\u001b[0m \u001b[38;2;244;10;0m₀.₀₀₉₉₆\u001b[0m acute\u001b[0m \u001b[38;2;229;25;0m₀.₀₂₃₈₆\u001b[0m shortness\u001b[0m \u001b[38;2;168;86;0m₀.₀₈₂₃₁\u001b[0m of\u001b[0m \u001b[38;2;225;29;0m₀.₀₂₈₂₈\u001b[0m breath\u001b[0m \u001b[38;2;98;156;0m₀.₁₄₈₀₇\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₁₆₄₀₅\u001b[0m GERD\u001b[0m \u001b[38;2;133;121;0m₀.₀₇₇₉₁\u001b[0m Hypertension \u001b[0m \u001b[38;2;155;99;0m₀.₀₆₄₀₁\u001b[0m \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medical_sentences = [\n",
        "    \"A 45-year-old obese man presents with severe chest pain and nausea.\",\n",
        "    \"An alcoholic woman complains of chronic liver pain and fatigue.\",\n",
        "    \"A diabetic patient reports uncontrolled blood sugar and recurring infections.\",\n",
        "    \"A 32-year-old drug addict presents with shortness of breath and severe cough.\",\n",
        "    \"A 70-year-old woman with hypertension complains of dizziness and confusion.\",\n",
        "    \"A 50-year-old smoker presents with persistent cough and weight loss.\",\n",
        "    \"An uncooperative elderly patient refuses treatment for chest pain and breathing difficulties.\",\n",
        "    \"A 28-year-old woman presents with anxiety, rapid heart rate, and panic attacks.\",\n",
        "    \"A rude man insists on a stronger medication for his back pain.\",\n",
        "    \"A 40-year-old patient with a history of drug abuse reports numbness in extremities and headaches.\",\n",
        "    \"An overweight child complains of knee pain and difficulty breathing during physical activity.\",\n",
        "    \"A 25-year-old man presents with fatigue, body aches, and fever after traveling abroad.\",\n",
        "    \"A noncompliant diabetic patient reports vision problems and frequent urination.\",\n",
        "    \"A disrespectful woman demands immediate treatment for her stomach pain.\",\n",
        "    \"A 60-year-old woman complains of shortness of breath and swelling in her legs.\",\n",
        "    \"A 70-year-old with a history of stroke presents with slurred speech and confusion.\",\n",
        "    \"An irritable man complains of chest tightness and dizziness after exercise.\",\n",
        "    \"A pregnant woman presents with abdominal pain and nausea.\",\n",
        "    \"A drug-seeking patient insists on opioids for chronic back pain.\",\n",
        "    \"A 50-year-old patient reports severe headaches and blurred vision.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "VjtDyR5CiLaR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pejorative_words = [\n",
        "    \"obese\", \"alcoholic\", \"drug addict\", \"uncooperative\", \"rude\", \"overweight\",\n",
        "    \"noncompliant\", \"disrespectful\", \"irritable\", \"drug-seeking\"\n",
        "]"
      ],
      "metadata": {
        "id": "YHcIy_ExiNDR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prejorative_sentences = []\n",
        "for sent  in medical_sentences:\n",
        "    for word in pejorative_words:\n",
        "        if word in sent.lower():\n",
        "          prejorative_sentences.append(sent)\n",
        "prejorative_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXnx-3mtxwb3",
        "outputId": "5d144a10-549a-41c6-fe14-6c3f92ee8417"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A 45-year-old obese man presents with severe chest pain and nausea.',\n",
              " 'An alcoholic woman complains of chronic liver pain and fatigue.',\n",
              " 'A 32-year-old drug addict presents with shortness of breath and severe cough.',\n",
              " 'An uncooperative elderly patient refuses treatment for chest pain and breathing difficulties.',\n",
              " 'A rude man insists on a stronger medication for his back pain.',\n",
              " 'An overweight child complains of knee pain and difficulty breathing during physical activity.',\n",
              " 'A noncompliant diabetic patient reports vision problems and frequent urination.',\n",
              " 'A disrespectful woman demands immediate treatment for her stomach pain.',\n",
              " 'An irritable man complains of chest tightness and dizziness after exercise.',\n",
              " 'A drug-seeking patient insists on opioids for chronic back pain.']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_prejorative_sentences = []\n",
        "for sent in prejorative_sentences:\n",
        "    for word in pejorative_words:\n",
        "        if word in sent.lower():\n",
        "            sent = sent.replace(word, \"\")\n",
        "    remove_prejorative_sentences.append(sent)\n",
        "\n",
        "remove_prejorative_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmZthhXyRNV",
        "outputId": "4097670f-da26-464f-c7d9-d9b68203d29c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A 45-year-old  man presents with severe chest pain and nausea.',\n",
              " 'An  woman complains of chronic liver pain and fatigue.',\n",
              " 'A 32-year-old  presents with shortness of breath and severe cough.',\n",
              " 'An  elderly patient refuses treatment for chest pain and breathing difficulties.',\n",
              " 'A  man insists on a stronger medication for his back pain.',\n",
              " 'An  child complains of knee pain and difficulty breathing during physical activity.',\n",
              " 'A  diabetic patient reports vision problems and frequent urination.',\n",
              " 'A  woman demands immediate treatment for her stomach pain.',\n",
              " 'An  man complains of chest tightness and dizziness after exercise.',\n",
              " 'A  patient insists on opioids for chronic back pain.']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in prejorative_sentences[:3]:\n",
        "  visualize_attention_and_predictions(sent, model, tokenizer, label_encoder, layer_num=-1, head_num=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um7KdwVxy8W4",
        "outputId": "bb786422-b5ea-47be-b2dd-6b1a577ae6f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;235;19;0m₀.₀₀₉₈₀\u001b[0m 45\u001b[0m \u001b[38;2;222;32;0m₀.₀₁₆₁₇\u001b[0m -\u001b[0m \u001b[38;2;250;4;0m₀.₀₀₂₃₆\u001b[0m year\u001b[0m \u001b[38;2;248;6;0m₀.₀₀₃₃₁\u001b[0m -\u001b[0m \u001b[38;2;253;1;0m₀.₀₀₀₈₈\u001b[0m old\u001b[0m \u001b[38;2;251;3;0m₀.₀₀₁₇₇\u001b[0m obese\u001b[0m \u001b[38;2;148;106;0m₀.₀₅₃₀₆\u001b[0m man\u001b[0m \u001b[38;2;223;31;0m₀.₀₁₅₈₁\u001b[0m presents\u001b[0m \u001b[38;2;176;78;0m₀.₀₃₉₀₉\u001b[0m with\u001b[0m \u001b[38;2;238;16;0m₀.₀₀₇₉₉\u001b[0m severe\u001b[0m \u001b[38;2;208;46;0m₀.₀₂₂₉₁\u001b[0m chest\u001b[0m \u001b[38;2;193;61;0m₀.₀₃₀₆₈\u001b[0m pain\u001b[0m \u001b[38;2;171;83;0m₀.₀₄₁₅₉\u001b[0m and\u001b[0m \u001b[38;2;222;32;0m₀.₀₁₅₉₆\u001b[0m \u001b[45mnausea\u001b[0m \u001b[38;2;0;255;0m₀.₁₂₆₆₁\u001b[0m .\u001b[0m \u001b[38;2;203;51;0m₀.₀₂₅₄₀\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₄₁₈₃₃\u001b[0m Chronic cholestasis\u001b[0m \u001b[38;2;230;24;0m₀.₀₄₀₁₃\u001b[0m Acne\u001b[0m \u001b[38;2;230;24;0m₀.₀₃₉₉₈\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "An\u001b[0m \u001b[38;2;221;33;0m₀.₀₁₈₆₀\u001b[0m alcoholic\u001b[0m \u001b[38;2;151;103;0m₀.₀₅₇₄₂\u001b[0m woman\u001b[0m \u001b[38;2;221;33;0m₀.₀₁₈₇₁\u001b[0m complains\u001b[0m \u001b[38;2;198;56;0m₀.₀₃₁₇₀\u001b[0m of\u001b[0m \u001b[38;2;220;34;0m₀.₀₁₉₁₅\u001b[0m chronic\u001b[0m \u001b[38;2;204;50;0m₀.₀₂₈₂₅\u001b[0m liver\u001b[0m \u001b[38;2;64;190;0m₀.₁₀₆₄₀\u001b[0m pain\u001b[0m \u001b[38;2;110;144;0m₀.₀₈₀₃₈\u001b[0m and\u001b[0m \u001b[38;2;216;38;0m₀.₀₂₁₄₄\u001b[0m \u001b[45mfatigue\u001b[0m \u001b[38;2;0;255;0m₀.₁₄₂₁₁\u001b[0m .\u001b[0m \u001b[38;2;215;39;0m₀.₀₂₂₁₁\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₀₉₀₅₈\u001b[0m Fungal infection\u001b[0m \u001b[38;2;90;164;0m₀.₀₅₈₅₁\u001b[0m Acne\u001b[0m \u001b[38;2;114;140;0m₀.₀₅₀₀₇\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;234;20;0m₀.₀₀₉₄₅\u001b[0m 32\u001b[0m \u001b[38;2;225;29;0m₀.₀₁₃₈₇\u001b[0m -\u001b[0m \u001b[38;2;247;7;0m₀.₀₀₃₄₈\u001b[0m year\u001b[0m \u001b[38;2;242;12;0m₀.₀₀₅₆₉\u001b[0m -\u001b[0m \u001b[38;2;251;3;0m₀.₀₀₁₇₅\u001b[0m old\u001b[0m \u001b[38;2;250;4;0m₀.₀₀₁₉₀\u001b[0m drug\u001b[0m \u001b[38;2;166;88;0m₀.₀₄₁₀₅\u001b[0m addict\u001b[0m \u001b[38;2;177;77;0m₀.₀₃₅₈₅\u001b[0m presents\u001b[0m \u001b[38;2;213;41;0m₀.₀₁₉₃₃\u001b[0m with\u001b[0m \u001b[38;2;240;14;0m₀.₀₀₆₆₄\u001b[0m shortness\u001b[0m \u001b[38;2;172;82;0m₀.₀₃₈₂₆\u001b[0m of\u001b[0m \u001b[38;2;209;45;0m₀.₀₂₁₂₄\u001b[0m breath\u001b[0m \u001b[38;2;45;209;0m₀.₀₉₇₄₀\u001b[0m and\u001b[0m \u001b[38;2;225;29;0m₀.₀₁₃₇₇\u001b[0m severe\u001b[0m \u001b[38;2;180;74;0m₀.₀₃₄₅₀\u001b[0m \u001b[45mcough\u001b[0m \u001b[38;2;0;255;0m₀.₁₁₈₅₆\u001b[0m .\u001b[0m \u001b[38;2;205;49;0m₀.₀₂₃₀₆\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mBronchial Asthma\u001b[0m \u001b[38;2;0;255;0m₀.₁₈₄₅₂\u001b[0m Heart attack\u001b[0m \u001b[38;2;92;162;0m₀.₁₁₇₃₅\u001b[0m Pneumonia\u001b[0m \u001b[38;2;153;101;0m₀.₀₇₃₅₄\u001b[0m \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in remove_prejorative_sentences[:3]:\n",
        "  visualize_attention_and_predictions(sent, model, tokenizer, label_encoder, layer_num=-1, head_num=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK9_1Cpy0F6C",
        "outputId": "9c0f02cc-c068-423c-a851-346356191766"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;233;21;0m₀.₀₁₁₂₃\u001b[0m 45\u001b[0m \u001b[38;2;222;32;0m₀.₀₁₆₄₂\u001b[0m -\u001b[0m \u001b[38;2;249;5;0m₀.₀₀₂₉₇\u001b[0m year\u001b[0m \u001b[38;2;246;8;0m₀.₀₀₄₁₁\u001b[0m -\u001b[0m \u001b[38;2;252;2;0m₀.₀₀₁₅₂\u001b[0m old\u001b[0m \u001b[38;2;249;5;0m₀.₀₀₂₅₆\u001b[0m man\u001b[0m \u001b[38;2;223;31;0m₀.₀₁₆₂₂\u001b[0m presents\u001b[0m \u001b[38;2;181;73;0m₀.₀₃₇₅₂\u001b[0m with\u001b[0m \u001b[38;2;240;14;0m₀.₀₀₇₅₈\u001b[0m severe\u001b[0m \u001b[38;2;212;42;0m₀.₀₂₁₆₁\u001b[0m chest\u001b[0m \u001b[38;2;192;62;0m₀.₀₃₁₈₂\u001b[0m pain\u001b[0m \u001b[38;2;160;94;0m₀.₀₄₈₂₉\u001b[0m and\u001b[0m \u001b[38;2;226;28;0m₀.₀₁₄₅₆\u001b[0m \u001b[45mnausea\u001b[0m \u001b[38;2;0;255;0m₀.₁₃₀₄₅\u001b[0m .\u001b[0m \u001b[38;2;204;50;0m₀.₀₂₅₇₀\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₄₇₇₅₉\u001b[0m Chronic cholestasis\u001b[0m \u001b[38;2;235;19;0m₀.₀₃₇₃₄\u001b[0m Acne\u001b[0m \u001b[38;2;237;17;0m₀.₀₃₁₈₄\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "An\u001b[0m \u001b[38;2;83;171;0m₀.₀₈₉₉₀\u001b[0m woman\u001b[0m \u001b[38;2;29;225;0m₀.₁₁₇₈₆\u001b[0m complains\u001b[0m \u001b[38;2;203;51;0m₀.₀₂₆₇₅\u001b[0m of\u001b[0m \u001b[38;2;232;22;0m₀.₀₁₁₉₅\u001b[0m chronic\u001b[0m \u001b[38;2;196;58;0m₀.₀₃₀₅₃\u001b[0m liver\u001b[0m \u001b[38;2;10;244;0m₀.₁₂₇₉₉\u001b[0m pain\u001b[0m \u001b[38;2;131;123;0m₀.₀₆₄₄₄\u001b[0m and\u001b[0m \u001b[38;2;224;30;0m₀.₀₁₆₀₀\u001b[0m \u001b[45mfatigue\u001b[0m \u001b[38;2;0;255;0m₀.₁₃₃₃₁\u001b[0m .\u001b[0m \u001b[38;2;217;37;0m₀.₀₁₉₅₃\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₁₃₂₉₁\u001b[0m Chronic cholestasis\u001b[0m \u001b[38;2;147;107;0m₀.₀₅₆₂₈\u001b[0m Fungal infection\u001b[0m \u001b[38;2;148;106;0m₀.₀₅₅₃₇\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;224;30;0m₀.₀₁₃₅₃\u001b[0m 32\u001b[0m \u001b[38;2;221;33;0m₀.₀₁₄₉₈\u001b[0m -\u001b[0m \u001b[38;2;245;9;0m₀.₀₀₄₀₅\u001b[0m year\u001b[0m \u001b[38;2;239;15;0m₀.₀₀₆₉₄\u001b[0m -\u001b[0m \u001b[38;2;248;6;0m₀.₀₀₂₈₇\u001b[0m old\u001b[0m \u001b[38;2;248;6;0m₀.₀₀₂₇₆\u001b[0m presents\u001b[0m \u001b[38;2;207;47;0m₀.₀₂₁₁₇\u001b[0m with\u001b[0m \u001b[38;2;239;15;0m₀.₀₀₇₀₃\u001b[0m shortness\u001b[0m \u001b[38;2;154;100;0m₀.₀₄₄₄₆\u001b[0m of\u001b[0m \u001b[38;2;197;57;0m₀.₀₂₅₅₈\u001b[0m breath\u001b[0m \u001b[38;2;8;246;0m₀.₁₀₈₈₉\u001b[0m and\u001b[0m \u001b[38;2;216;38;0m₀.₀₁₇₀₉\u001b[0m severe\u001b[0m \u001b[38;2;157;97;0m₀.₀₄₂₉₀\u001b[0m \u001b[45mcough\u001b[0m \u001b[38;2;0;255;0m₀.₁₁₂₅₆\u001b[0m .\u001b[0m \u001b[38;2;181;73;0m₀.₀₃₂₄₁\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mBronchial Asthma\u001b[0m \u001b[38;2;0;255;0m₀.₁₈₅₁₃\u001b[0m Heart attack\u001b[0m \u001b[38;2;55;199;0m₀.₁₄₄₆₈\u001b[0m Pneumonia\u001b[0m \u001b[38;2;184;70;0m₀.₀₅₁₅₀\u001b[0m \n",
            "\n"
          ]
        }
      ]
    }
  ]
}