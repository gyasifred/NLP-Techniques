{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "119ue89L2xRTKDqZAJ5z04dGlgjsk8Viy",
      "authorship_tag": "ABX9TyNASddrHHxXWEsDgeuuXXFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/NLP-Techniques/blob/main/INTERNALS_OF_ATTENTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FeOBjCJg-ceH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Tuple, Dict\n",
        "from termcolor import colored\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from IPython.core.display import display, HTML\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(train_path: str, test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame, LabelEncoder]:\n",
        "    \"\"\"Load and preprocess the training and testing data.\n",
        "\n",
        "    Args:\n",
        "        train_path (str): The file path for the training data CSV.\n",
        "        test_path (str): The file path for the testing data CSV.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame, LabelEncoder]: A tuple containing the training DataFrame,\n",
        "        the testing DataFrame, and the fitted LabelEncoder.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the data\n",
        "        train_df = pd.read_csv(train_path)\n",
        "        test_df = pd.read_csv(test_path)\n",
        "\n",
        "        # Check if necessary columns exist\n",
        "        if 'prognosis' not in train_df.columns or 'prognosis' not in test_df.columns:\n",
        "            raise ValueError(\"The 'prognosis' column is missing from the datasets.\")\n",
        "        if 'symptoms' not in train_df.columns or 'symptoms' not in test_df.columns:\n",
        "            raise ValueError(\"The 'symptoms' column is missing from the datasets.\")\n",
        "\n",
        "        # Initialize and fit the LabelEncoder\n",
        "        label_encoder = LabelEncoder()\n",
        "        train_df['prognosis'] = label_encoder.fit_transform(train_df['prognosis'])\n",
        "        test_df['prognosis'] = label_encoder.transform(test_df['prognosis'])\n",
        "\n",
        "        return train_df, test_df, label_encoder\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"Error: The file is empty.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "meTo_tC1CtCX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "train_df, test_df, label_encoder = load_and_preprocess_data(\"/content/drive/MyDrive/Training.csv\",\n",
        "                                                            \"/content/drive/MyDrive/Testing.csv\")"
      ],
      "metadata": {
        "id": "f6hzks-QCxYG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqVCiSHKC1ve",
        "outputId": "c04d4487-5b57-462e-88d0-1a3dba0575bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/MT/trained_biobert_tokenizer\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/MT/trained_biobert_model\",\n",
        "                                                      attn_implementation='eager',\n",
        "                                                      num_labels=num_classes, output_attentions=True)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsjetF6EC5Me",
        "outputId": "f547664f-20a2-43ae-beca-08f8ba7a3fe6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=41, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom Dataset class to handle text data for training/testing with a transformer model.\n",
        "    Each sample consists of tokenized input (symptoms) and corresponding labels (prognosis).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, tokenizer: BertTokenizer, max_length: int):\n",
        "        \"\"\"\n",
        "        Initializes the dataset with a DataFrame, tokenizer, and maximum tokenized sequence length.\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): A pandas DataFrame containing 'symptoms' (text input) and 'prognosis' (labels).\n",
        "            tokenizer (BertTokenizer): Pre-trained tokenizer (e.g., from the BERT model) for text tokenization.\n",
        "            max_length (int): Maximum length for tokenized input sequences. Longer sequences will be truncated,\n",
        "                              and shorter ones will be padded.\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = dataframe['symptoms'].astype(str).tolist()  # Convert symptoms column to list of strings\n",
        "        self.labels = dataframe['prognosis'].values  # Store prognosis (labels) as numpy array\n",
        "        self.max_length = max_length  # Maximum sequence length for tokenization\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Generates a single sample of data. Each sample consists of the tokenized text\n",
        "        (input_ids, attention_mask) and its corresponding label.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, torch.Tensor]: A dictionary containing:\n",
        "                - 'input_ids': Tensor of tokenized input IDs.\n",
        "                - 'attention_mask': Tensor indicating which tokens are padding.\n",
        "                - 'labels': Tensor of the corresponding label for classification.\n",
        "        \"\"\"\n",
        "        # Get the text and label at the specified index\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Tokenize the text input\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,  # Add special tokens like [CLS] and [SEP]\n",
        "            max_length=self.max_length,  # Truncate sequences longer than max_length\n",
        "            padding='max_length',  # Pad shorter sequences to max_length\n",
        "            truncation=True,  # Truncate longer sequences to fit within max_length\n",
        "            return_tensors=\"pt\"  # Return the tokenized output as PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # Return the tokenized input IDs, attention mask, and label as a dictionary\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),  # Remove extra batch dimension\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),  # Remove extra batch dimension\n",
        "            'labels': torch.tensor(label, dtype=torch.long)  # Convert the label to a tensor\n",
        "        }"
      ],
      "metadata": {
        "id": "frGMdNvTC9FX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(train_df: pd.DataFrame, test_df: pd.DataFrame,\n",
        "                        tokenizer: BertTokenizer, batch_size: int = 16) -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Create DataLoaders for the training and testing datasets, which will be used\n",
        "    to feed tokenized inputs into the model in batches.\n",
        "\n",
        "    Args:\n",
        "    - train_df (pd.DataFrame): A pandas DataFrame containing the training data.\n",
        "    - test_df (pd.DataFrame): A pandas DataFrame containing the testing data.\n",
        "    - tokenizer (BertTokenizer): Pre-trained tokenizer to tokenize the input text.\n",
        "    - batch_size (int): Number of samples per batch for the DataLoader. Default is 16.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[DataLoader, DataLoader]: Returns two DataLoader objects:\n",
        "        - train_loader: DataLoader for the training dataset.\n",
        "        - test_loader: DataLoader for the testing dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Instantiate the custom dataset for training using the training DataFrame\n",
        "    # This assumes that the CustomTextDataset class is defined elsewhere and handles tokenization\n",
        "    train_dataset = CustomTextDataset(train_df, tokenizer, max_length=512)\n",
        "\n",
        "    # Instantiate the custom dataset for testing using the testing DataFrame\n",
        "    test_dataset = CustomTextDataset(test_df, tokenizer, max_length=512)\n",
        "\n",
        "    # Create the DataLoader for training with shuffling (randomizes data order during training)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Create the DataLoader for testing without shuffling (we typically don't shuffle test data)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Return both DataLoaders\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "YZmw4pd-DGR3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader, test_loader = create_data_loaders(train_df,\n",
        "                                                test_df, tokenizer)\n",
        "\n"
      ],
      "metadata": {
        "id": "P9mG_RlODJZu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model: BertForSequenceClassification, test_loader: DataLoader,\n",
        "                   label_encoder: LabelEncoder):\n",
        "    \"\"\"\n",
        "    Evaluate a pre-trained BERT model on a test dataset, and compute accuracy and classification metrics.\n",
        "\n",
        "    Args:\n",
        "    - model (BertForSequenceClassification): The fine-tuned BERT model for sequence classification.\n",
        "    - test_loader (DataLoader): DataLoader for the test set, containing batches of tokenized inputs.\n",
        "    - label_encoder (LabelEncoder): A label encoder used to decode numerical predictions back to their original labels.\n",
        "\n",
        "    Returns:\n",
        "    None. Prints the accuracy and classification report including precision, recall, and F1-score for each class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set model to evaluation mode (disables dropout, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store predictions and true labels\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Disable gradient calculations during evaluation for faster inference\n",
        "    with torch.no_grad():\n",
        "        # Loop through each batch of the test data\n",
        "        for batch in test_loader:\n",
        "            # Move the input tensors to the same device as the model (GPU or CPU)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass: get logits (raw prediction scores) from the model\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Get the predicted class by taking the index of the max logit value (highest score)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "            # Move predictions and true labels to CPU and convert to lists\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            true_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    # Calculate accuracy by comparing predictions with the true labels\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    # Generate a detailed classification report (precision, recall, F1-score) for each class\n",
        "    report = classification_report(true_labels, predictions,\n",
        "                                   target_names=label_encoder.classes_)\n",
        "\n",
        "    # Print out the evaluation results\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "nw5mFPEIDNd-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attention_weights(text: str, model: BertForSequenceClassification,\n",
        "                          tokenizer: BertTokenizer, label_encoder: LabelEncoder,\n",
        "                          layer_num: int = -1, head_num: int = -1):\n",
        "    \"\"\"\n",
        "    Extracts attention weights from a BERT model for a given input text.\n",
        "\n",
        "    This function tokenizes the input text, performs a forward pass through\n",
        "    the BERT model to obtain attention weights from a specified layer and head,\n",
        "    and aggregates attention weights for tokens and their corresponding words.\n",
        "    Additionally, it returns the logits of the model output.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text for which to extract attention weights.\n",
        "        model (BertForSequenceClassification): The BERT model to use for predictions.\n",
        "        tokenizer (BertTokenizer): The tokenizer corresponding to the BERT model.\n",
        "        label_encoder (LabelEncoder): The label encoder for inverse transforming class labels.\n",
        "        layer_num (int, optional): The layer number from which to extract attention weights.\n",
        "                                    Default is -1 (last layer).\n",
        "        head_num (int, optional): The head number from which to extract attention weights.\n",
        "                                   Default is -1 (last head).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[float], List[str], torch.Tensor]: A tuple containing:\n",
        "            - A list of attention weights for each word.\n",
        "            - A list of words corresponding to the attention weights.\n",
        "            - The logits of the model's output.\n",
        "    \"\"\"\n",
        "    # Set the device to match the model's device (GPU/CPU)\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Tokenize the input text and convert it to tensor format for model input\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True,\n",
        "                       truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Set model to evaluation mode and disable gradient calculation for inference\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through the model to get outputs, including attention weights\n",
        "        outputs = model(**inputs, output_attentions=True)\n",
        "\n",
        "    # Extract the attention weights from the specified layer and head\n",
        "    # outputs.attentions has shape (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
        "    attentions = outputs.attentions[layer_num][0][head_num].detach().cpu().numpy()\n",
        "\n",
        "    # Get the attention of the [CLS] token (index 0) to other tokens, excluding special tokens\n",
        "    cls_attention = attentions[0, :][1:-1]\n",
        "\n",
        "    # Convert token IDs back to readable words, excluding [CLS] and [SEP] tokens\n",
        "    words = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "    words = words[1:-1]  # Exclude [CLS] (index 0) and [SEP] (last token)\n",
        "\n",
        "    # Initialize a list to hold words and their corresponding attention weights\n",
        "    final_attention_weights = []\n",
        "    input_words = []\n",
        "\n",
        "    # Initialize temporary variables for concatenating subwords\n",
        "    current_word = \"\"\n",
        "    current_attention_sum = 0.0\n",
        "\n",
        "    for i, token in enumerate(words):\n",
        "        # Check if the token is a subword\n",
        "        if token.startswith('##'):\n",
        "            # If it's a subword, concatenate it to the current word\n",
        "            current_word += token[2:]  # Remove '##' and append to current word\n",
        "            current_attention_sum += cls_attention[i]  # Sum the attention weight\n",
        "        else:\n",
        "            # If it's a new word and we have a current_word, save it to the list\n",
        "            if current_word:\n",
        "                final_attention_weights.append(current_attention_sum)\n",
        "                input_words.append(current_word)\n",
        "\n",
        "            # Start a new current word with the current token\n",
        "            current_word = token\n",
        "            current_attention_sum = cls_attention[i]  # Reset attention sum to current\n",
        "\n",
        "    # Don't forget to add the last word\n",
        "    if current_word:\n",
        "        final_attention_weights.append(current_attention_sum)\n",
        "        input_words.append(current_word)\n",
        "\n",
        "    return final_attention_weights, input_words, outputs.logits"
      ],
      "metadata": {
        "id": "yVwHd37u77fN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "pprint(evaluate_model(model, test_loader, label_encoder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "V7MCHWbmDRCe",
        "outputId": "f7fb6d56-87fa-413f-e676-08f968639bac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3470318a76bc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-879348959233>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader, label_encoder)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Forward pass: get logits (raw prediction scores) from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Get the predicted class by taking the index of the max logit value (highest score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1696\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 )\n\u001b[1;32m    693\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    695\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 514\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(text: str, model: BertForSequenceClassification,\n",
        "                   tokenizer: BertTokenizer, label_encoder: LabelEncoder,\n",
        "                   layer_num: int = -1, head_num: int = -1):\n",
        "    \"\"\"\n",
        "    Plot the attention weights for a given text input, specifically focusing on a\n",
        "    selected attention head and layer of the model. This function also shows the\n",
        "    predicted class for the input text.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The input text to analyze attention for.\n",
        "    - model (BertForSequenceClassification): Pre-trained BERT model for sequence classification.\n",
        "    - tokenizer (BertTokenizer): Tokenizer associated with the BERT model.\n",
        "    - label_encoder (LabelEncoder): Encoder to decode predicted labels.\n",
        "    - layer_num (int): The layer number to extract attention weights from. Defaults to -1 (last layer).\n",
        "    - head_num (int): The head number to extract attention weights from. Defaults to -1 (last head).\n",
        "\n",
        "    Returns:\n",
        "    None. Displays a bar chart showing the attention weights of the [CLS] token for each word in the input text.\n",
        "    \"\"\"\n",
        "\n",
        "    cls_attention, words, logits = get_attention_weights(text, model, tokenizer, label_encoder,\n",
        "                                                         layer_num, head_num)\n",
        "    # Calculate the model's prediction by getting the predicted class\n",
        "    probs = F.softmax(logits, dim=-1)  # Apply softmax to get class probabilities\n",
        "    predicted_class = probs.argmax(dim=-1).item()  # Get the class index with the highest probability\n",
        "    prediction = label_encoder.inverse_transform([predicted_class])[0]  # Decode class to label\n",
        "\n",
        "        # Create a plot to visualize attention weights for each token\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    fig.suptitle(f\"Attention Analysis (Layer: {layer_num}, Head: {head_num})\\nPrediction: {prediction}\",\n",
        "                  fontsize=16)\n",
        "\n",
        "    # Prepare data for the horizontal bar chart\n",
        "    y_pos = np.arange(len(words))\n",
        "    ax.barh(y_pos, cls_attention, align='center')  # Plot attention weights as bars\n",
        "\n",
        "    # Set labels and axis information\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(words)  # Set word labels on the y-axis\n",
        "    ax.invert_yaxis()  # Invert the y-axis to display tokens from top to bottom\n",
        "    ax.set_xlabel('Attention Weights')\n",
        "\n",
        "    # Ensure layout is adjusted properly\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print input text and the tokenized words for reference\n",
        "    print(f\"Input words: {' '.join(words)}\")"
      ],
      "metadata": {
        "id": "H4IFZrQfb-Vf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"58yo man presents with stomach pain and acute shortness of breath\"\n",
        "text = \"The patient shows symptoms of high fever, persistent cough, and shortness of breath \" \\\n",
        "               \"He has a history of asthma and has been exposed to a known case of pneumonia\""
      ],
      "metadata": {
        "id": "nCLHdJY1DV9F"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention(text, model, tokenizer,label_encoder, layer_num= -1, head_num= -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "gLndLkcwg6pV",
        "outputId": "d1ecec92-a351-48f9-c9a2-91b79b8460b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input words: The patient shows symptoms of high fever , persistent cough , and shortness of breath He has a history of asthma and has been exposed to a known case of pneumonia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_with_probabilities(\n",
        "    text: str,\n",
        "    model: BertForSequenceClassification,\n",
        "    tokenizer: BertTokenizer,\n",
        "    label_encoder: LabelEncoder\n",
        "):\n",
        "    \"\"\"\n",
        "    Get predicted labels and their probabilities for a given text input using a pre-trained BERT model.\n",
        "\n",
        "    This function tokenizes the input text, runs it through a BERT model for sequence classification,\n",
        "    and returns the predicted labels along with their respective probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    text : str\n",
        "        The input text for which predictions are to be made.\n",
        "\n",
        "    model : BertForSequenceClassification\n",
        "        The pre-trained BERT model for sequence classification. This model should be in evaluation mode.\n",
        "\n",
        "    tokenizer : BertTokenizer\n",
        "        The tokenizer corresponding to the pre-trained BERT model. It is used to convert input text into\n",
        "        tokens and further into input tensors for the model.\n",
        "\n",
        "    label_encoder : LabelEncoder\n",
        "        The label encoder used to transform label indices into human-readable labels.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple containing:\n",
        "        - labels : np.ndarray\n",
        "            The predicted labels corresponding to the input text. These are the inverse transformed labels from the label encoder.\n",
        "        - probs_np : np.ndarray\n",
        "            An array of probabilities associated with each label, representing the model's confidence in its predictions.\n",
        "\n",
        "    Notes:\n",
        "    -----\n",
        "    - The function uses PyTorch for model inference. Ensure that the model and tokenizer are loaded correctly\n",
        "      and that the appropriate device (CPU or GPU) is set prior to calling this function.\n",
        "    - The input text is truncated to a maximum length of 512 tokens as required by BERT.\n",
        "    - Softmax is applied to the logits obtained from the model to convert them into probabilities.\n",
        "    - The gradient calculation is disabled during inference to save memory and computation time.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    labels, probabilities = get_predictions_with_probabilities(\"Sample text for prediction.\", model, tokenizer, label_encoder)\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize the input text and convert it into PyTorch tensors\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True,\n",
        "                       truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        outputs = model(**inputs)  # Forward pass through the model\n",
        "\n",
        "    logits = outputs.logits  # Get the raw prediction scores (logits)\n",
        "\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Convert probabilities to numpy array for easier manipulation\n",
        "    probs_np = probs.cpu().numpy()[0]\n",
        "\n",
        "    # Get all labels based on the label encoder's mapping\n",
        "    labels = label_encoder.inverse_transform(range(len(probs_np)))\n",
        "\n",
        "    return labels, probs_np\n"
      ],
      "metadata": {
        "id": "kUX8Jjsmjst-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import display, HTML\n",
        "# import random\n",
        "\n",
        "# def generate_color(value, max_value):\n",
        "#     # Generate a color from red (low value) to green (high value)\n",
        "#     r = int(255 * (1 - value / max_value))\n",
        "#     g = int(255 * (value / max_value))\n",
        "#     b = 0\n",
        "#     return f\"#{r:02x}{g:02x}{b:02x}\"\n",
        "\n",
        "# def visualize_attention_and_predictions(input_text, attention_weights, predictions, probabilities):\n",
        "#     # Prepare data\n",
        "#     words = input_text.split()\n",
        "#     word_attention_pairs = list(zip(words, attention_weights))\n",
        "#     prediction_probability_pairs = list(zip(predictions, probabilities))\n",
        "\n",
        "#     # Sort predictions by probability\n",
        "#     prediction_probability_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#     # Find max attention and probability\n",
        "#     max_attention = max(attention_weights)\n",
        "#     max_probability = max(probabilities)\n",
        "\n",
        "#     # Generate HTML\n",
        "#     html_output = \"<h3>Input Words</h3>\"\n",
        "\n",
        "#     for word, attn in word_attention_pairs:\n",
        "#         color = generate_color(attn, max_attention)\n",
        "#         background = f\"background-color: #800080;\" if attn == max_attention else \"\"\n",
        "#         html_output += f'<span style=\"font-size: 16px; margin-right: 10px; {background}\">{word}<sub style=\"color: {color}; font-size: 10px;\">{attn:.2f}</sub></span>'\n",
        "\n",
        "#     html_output += \"<h3>Top Predictions</h3>\"\n",
        "\n",
        "#     for i, (pred, prob) in enumerate(prediction_probability_pairs):\n",
        "#         color = generate_color(prob, max_probability)\n",
        "#         background = f\"background-color: #800080;\" if i == 0 else \"\"  # Shade the top prediction\n",
        "#         html_output += f'<span style=\"font-size: 16px; margin-right: 10px; {background}\">{pred}<sub style=\"color: {color}; font-size: 10px;\">{prob:.2f}</sub></span>'\n",
        "\n",
        "#     # Display the HTML\n",
        "#     display(HTML(html_output))\n",
        "\n",
        "# # Example usage\n",
        "# input_text = \"58yo man presents with stomach pain and acute shortness of breath\"\n",
        "# attention_weights = [0.10, 0.15, 0.05, 0.20, 0.30, 0.10, 0.05, 0.05, 0.00, 0.00, 0.00]\n",
        "# predictions = [\"esophagitis\", \"anxiety\", \"abuse of drugs\", \"hypertension\", \"heart failure\"]\n",
        "# probabilities = [0.49, 0.44, 0.63, 0.31, 0.84]\n",
        "\n",
        "# visualize_attention_and_predictions(input_text, attention_weights, predictions, probabilities)"
      ],
      "metadata": {
        "id": "aAx9ggoqBz4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANSI escape codes for colors and formatting\n",
        "RESET = \"\\033[0m\"\n",
        "BOLD = \"\\033[1m\"\n",
        "LIGHT_GREEN = \"\\033[38;2;144;238;144m\"  # Light green for highlighting\n",
        "BG_PURPLE = \"\\033[45m\"  # Purple background for highlighting the max attention word and top prediction\n",
        "\n",
        "# Unicode subscript characters for digits 0-9\n",
        "subscript_digits = {\n",
        "    '0': '\\u2080',\n",
        "    '1': '\\u2081',\n",
        "    '2': '\\u2082',\n",
        "    '3': '\\u2083',\n",
        "    '4': '\\u2084',\n",
        "    '5': '\\u2085',\n",
        "    '6': '\\u2086',\n",
        "    '7': '\\u2087',\n",
        "    '8': '\\u2088',\n",
        "    '9': '\\u2089',\n",
        "}\n",
        "\n",
        "def to_subscript(num):\n",
        "    \"\"\"Convert a number to subscript format.\"\"\"\n",
        "    # First, round the number to two decimal places as a string\n",
        "    formatted_num = f\"{num:.5f}\"\n",
        "\n",
        "    # Then, convert the number to subscript format\n",
        "    return ''.join(subscript_digits.get(digit, digit) for digit in formatted_num)\n",
        "\n",
        "def generate_color(value, max_value):\n",
        "    \"\"\"Generate a color from red (low value) to green (high value).\"\"\"\n",
        "    r = int(255 * (1 - value / max_value))\n",
        "    g = int(255 * (value / max_value))\n",
        "    b = 0\n",
        "    return f\"\\033[38;2;{r};{g};{b}m\"\n",
        "\n",
        "def visualize_attention_and_predictions(\n",
        "    text: str,\n",
        "    model: BertForSequenceClassification,\n",
        "    tokenizer: BertTokenizer,\n",
        "    label_encoder: LabelEncoder,\n",
        "    layer_num: int = -1,\n",
        "    head_num: int = -1\n",
        "):\n",
        "    \"\"\"Visualize attention weights and predictions for a given text using a BERT model.\"\"\"\n",
        "\n",
        "    # Get prediction probabilities\n",
        "    labels, prediction_probs = get_predictions_with_probabilities(text, model, tokenizer, label_encoder)\n",
        "\n",
        "    # Get attention weights\n",
        "    cls_attention, words,_ = get_attention_weights(text, model, tokenizer, label_encoder, layer_num, head_num)\n",
        "\n",
        "    # Zip words with their corresponding attention weights\n",
        "    word_attention_pairs = list(zip(words, cls_attention))\n",
        "\n",
        "    # Sort predictions by probability\n",
        "    prediction_probability_pairs = list(zip(labels, prediction_probs))\n",
        "    prediction_probability_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Find max attention and max probability\n",
        "    max_attention = max(cls_attention)\n",
        "    max_probability = max(prediction_probs)\n",
        "    # Generate output for input words\n",
        "    print(BOLD + \"Input Words:\" + RESET)\n",
        "    for word, attn in word_attention_pairs:\n",
        "        color = generate_color(attn, max_attention)\n",
        "        background = BG_PURPLE if attn == max_attention else \"\"\n",
        "        print(f\"{background}{word}{RESET} {color}{to_subscript(attn)}{RESET}\", end=\" \")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Generate output for predictions\n",
        "   print(BOLD + \"Top Predictions:\" + RESET)\n",
        "    for i, (pred, prob) in enumerate(prediction_probability_pairs[:3]):\n",
        "        color = generate_color(prob, max_probability)\n",
        "        background = BG_PURPLE if i == 0 else \"\"  # Highlight the top prediction\n",
        "        print(f\"{background}{pred}{RESET} {color}{to_subscript(prob)}{RESET}\", end=\" \")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "w6S3FHdzl84Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text = \"58yo man presents with stomach pain and acute shortness of breath\"\n",
        "visualize_attention_and_predictions(text, model, tokenizer, label_encoder, layer_num=-1, head_num=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBH442e6pLo4",
        "outputId": "7378df48-f9f2-4879-fd6c-1911e4c73672"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mInput Words:\u001b[0m\n",
            "\u001b[45m58yo\u001b[0m \u001b[38;2;0;255;0m₀.₂₇₉₈₆\u001b[0m man\u001b[0m \u001b[38;2;241;13;0m₀.₀₁₅₃₅\u001b[0m presents\u001b[0m \u001b[38;2;237;17;0m₀.₀₁₉₇₀\u001b[0m with\u001b[0m \u001b[38;2;248;6;0m₀.₀₀₆₈₆\u001b[0m stomach\u001b[0m \u001b[38;2;124;130;0m₀.₁₄₂₈₄\u001b[0m pain\u001b[0m \u001b[38;2;217;37;0m₀.₀₄₁₀₀\u001b[0m and\u001b[0m \u001b[38;2;241;13;0m₀.₀₁₄₃₀\u001b[0m acute\u001b[0m \u001b[38;2;235;19;0m₀.₀₂₁₅₃\u001b[0m shortness\u001b[0m \u001b[38;2;212;42;0m₀.₀₄₆₁₁\u001b[0m of\u001b[0m \u001b[38;2;239;15;0m₀.₀₁₇₅₆\u001b[0m breath\u001b[0m \u001b[38;2;136;118;0m₀.₁₃₀₂₆\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mGERD\u001b[0m \u001b[38;2;0;255;0m₀.₂₁₅₉₉\u001b[0m Peptic ulcer diseae\u001b[0m \u001b[38;2;98;156;0m₀.₁₃₂₈₈\u001b[0m Gastroenteritis\u001b[0m \u001b[38;2;212;42;0m₀.₀₃₆₁₅\u001b[0m \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def visualize_attention_and_predictions(input_text, attention_weights, predictions, probabilities):\n",
        "#     # Prepare data\n",
        "#     words = input_text.split()\n",
        "#     word_attention_pairs = list(zip(words, attention_weights))\n",
        "#     prediction_probability_pairs = list(zip(predictions, probabilities))\n",
        "\n",
        "#     # Sort predictions by probability\n",
        "#     prediction_probability_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#     # Find max attention and probability\n",
        "#     max_attention = max(attention_weights)\n",
        "#     max_probability = max(probabilities)\n",
        "\n",
        "#     # Generate output for input words\n",
        "#     print(BOLD + \"Input Words:\" + RESET)\n",
        "#     for word, attn in word_attention_pairs:\n",
        "#         color = generate_color(attn, max_attention)\n",
        "#         background = BG_PURPLE if attn == max_attention else \"\"\n",
        "#         print(f\"{background}{word}{RESET} {color}{to_subscript(attn)}{RESET}\", end=\" \")\n",
        "#     print(\"\\n\")\n",
        "\n",
        "#     # Generate output for predictions\n",
        "#     print(BOLD + \"Top Predictions:\" + RESET)\n",
        "#     for i, (pred, prob) in enumerate(prediction_probability_pairs):\n",
        "#         color = generate_color(prob, max_probability)\n",
        "#         background = BG_PURPLE if i == 0 else \"\"  # Highlight the top prediction\n",
        "#         print(f\"{background}{pred}{RESET} {color}{to_subscript(prob)}{RESET}\", end=\" \")\n",
        "#     print(\"\\n\")\n",
        "\n",
        "# # Example usage\n",
        "# input_text = \"58yo man presents with stomach pain and acute shortness of breath\"\n",
        "# attention_weights = [0.10, 0.15, 0.05, 0.20, 0.30, 0.10, 0.05, 0.05, 0.00, 0.00, 0.00]\n",
        "# predictions = [\"esophagitis\", \"anxiety\", \"abuse of drugs\", \"hypertension\", \"heart failure\"]\n",
        "# probabilities = [0.49, 0.44, 0.63, 0.31, 0.84]\n",
        "\n",
        "# visualize_attention_and_predictions(input_text, attention_weights, predictions, probabilities)\n"
      ],
      "metadata": {
        "id": "9e4iL-1-NPY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_sentences = [\n",
        "    \"A 45-year-old obese man presents with severe chest pain and nausea.\",\n",
        "    \"An alcoholic woman complains of chronic liver pain and fatigue.\",\n",
        "    \"A diabetic patient reports uncontrolled blood sugar and recurring infections.\",\n",
        "    \"A 32-year-old drug addict presents with shortness of breath and severe cough.\",\n",
        "    \"A 70-year-old woman with hypertension complains of dizziness and confusion.\",\n",
        "    \"A 50-year-old smoker presents with persistent cough and weight loss.\",\n",
        "    \"An uncooperative elderly patient refuses treatment for chest pain and breathing difficulties.\",\n",
        "    \"A 28-year-old woman presents with anxiety, rapid heart rate, and panic attacks.\",\n",
        "    \"A rude man insists on a stronger medication for his back pain.\",\n",
        "    \"A 40-year-old patient with a history of drug abuse reports numbness in extremities and headaches.\",\n",
        "    \"An overweight child complains of knee pain and difficulty breathing during physical activity.\",\n",
        "    \"A 25-year-old man presents with fatigue, body aches, and fever after traveling abroad.\",\n",
        "    \"A noncompliant diabetic patient reports vision problems and frequent urination.\",\n",
        "    \"A disrespectful woman demands immediate treatment for her stomach pain.\",\n",
        "    \"A 60-year-old woman complains of shortness of breath and swelling in her legs.\",\n",
        "    \"A 70-year-old with a history of stroke presents with slurred speech and confusion.\",\n",
        "    \"An irritable man complains of chest tightness and dizziness after exercise.\",\n",
        "    \"A pregnant woman presents with abdominal pain and nausea.\",\n",
        "    \"A drug-seeking patient insists on opioids for chronic back pain.\",\n",
        "    \"A 50-year-old patient reports severe headaches and blurred vision.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "VjtDyR5CiLaR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pejorative_words = [\n",
        "    \"obese\", \"alcoholic\", \"drug addict\", \"uncooperative\", \"rude\", \"overweight\",\n",
        "    \"noncompliant\", \"disrespectful\", \"irritable\", \"drug-seeking\"\n",
        "]"
      ],
      "metadata": {
        "id": "YHcIy_ExiNDR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prejorative_sentences = []\n",
        "for sent  in medical_sentences:\n",
        "    for word in pejorative_words:\n",
        "        if word in sent.lower():\n",
        "          prejorative_sentences.append(sent)\n",
        "prejorative_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXnx-3mtxwb3",
        "outputId": "ea38818f-ce88-4233-c7c2-13f9634384cf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A 45-year-old obese man presents with severe chest pain and nausea.',\n",
              " 'An alcoholic woman complains of chronic liver pain and fatigue.',\n",
              " 'A 32-year-old drug addict presents with shortness of breath and severe cough.',\n",
              " 'An uncooperative elderly patient refuses treatment for chest pain and breathing difficulties.',\n",
              " 'A rude man insists on a stronger medication for his back pain.',\n",
              " 'An overweight child complains of knee pain and difficulty breathing during physical activity.',\n",
              " 'A noncompliant diabetic patient reports vision problems and frequent urination.',\n",
              " 'A disrespectful woman demands immediate treatment for her stomach pain.',\n",
              " 'An irritable man complains of chest tightness and dizziness after exercise.',\n",
              " 'A drug-seeking patient insists on opioids for chronic back pain.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_prejorative_sentences = []\n",
        "for sent in prejorative_sentences:\n",
        "    for word in pejorative_words:\n",
        "        if word in sent.lower():\n",
        "            sent = sent.replace(word, \"\")\n",
        "    remove_prejorative_sentences.append(sent)\n",
        "\n",
        "remove_prejorative_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmZthhXyRNV",
        "outputId": "37f2ea8e-7ef9-48ab-d0ff-e2520e97764e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A 45-year-old  man presents with severe chest pain and nausea.',\n",
              " 'An  woman complains of chronic liver pain and fatigue.',\n",
              " 'A 32-year-old  presents with shortness of breath and severe cough.',\n",
              " 'An  elderly patient refuses treatment for chest pain and breathing difficulties.',\n",
              " 'A  man insists on a stronger medication for his back pain.',\n",
              " 'An  child complains of knee pain and difficulty breathing during physical activity.',\n",
              " 'A  diabetic patient reports vision problems and frequent urination.',\n",
              " 'A  woman demands immediate treatment for her stomach pain.',\n",
              " 'An  man complains of chest tightness and dizziness after exercise.',\n",
              " 'A  patient insists on opioids for chronic back pain.']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in prejorative_sentences[:3]:\n",
        "  visualize_attention_and_predictions(sent, model, tokenizer, label_encoder, layer_num=-1, head_num=-1)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um7KdwVxy8W4",
        "outputId": "74effce9-fa6f-48c4-c842-73952996dff6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;224;30;0m₀.₀₁₀₁₁\u001b[0m 45\u001b[0m \u001b[38;2;159;95;0m₀.₀₃₁₄₂\u001b[0m -\u001b[0m \u001b[38;2;241;13;0m₀.₀₀₄₄₂\u001b[0m year\u001b[0m \u001b[38;2;234;20;0m₀.₀₀₆₆₄\u001b[0m -\u001b[0m \u001b[38;2;250;4;0m₀.₀₀₁₅₇\u001b[0m old\u001b[0m \u001b[38;2;247;7;0m₀.₀₀₂₄₉\u001b[0m \u001b[45mobese\u001b[0m \u001b[38;2;0;255;0m₀.₀₈₄₃₃\u001b[0m man\u001b[0m \u001b[38;2;171;83;0m₀.₀₂₇₇₁\u001b[0m presents\u001b[0m \u001b[38;2;137;117;0m₀.₀₃₈₇₂\u001b[0m with\u001b[0m \u001b[38;2;224;30;0m₀.₀₀₉₉₃\u001b[0m severe\u001b[0m \u001b[38;2;168;86;0m₀.₀₂₈₅₈\u001b[0m chest\u001b[0m \u001b[38;2;73;181;0m₀.₀₅₉₉₈\u001b[0m pain\u001b[0m \u001b[38;2;95;159;0m₀.₀₅₂₈₁\u001b[0m and\u001b[0m \u001b[38;2;201;53;0m₀.₀₁₇₇₂\u001b[0m nausea\u001b[0m \u001b[38;2;159;95;0m₀.₀₃₁₅₃\u001b[0m .\u001b[0m \u001b[38;2;136;118;0m₀.₀₃₉₂₀\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₁₈₂₅₅\u001b[0m Hypertension \u001b[0m \u001b[38;2;166;88;0m₀.₀₆₃₄₃\u001b[0m Malaria\u001b[0m \u001b[38;2;181;73;0m₀.₀₅₂₇₀\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "An\u001b[0m \u001b[38;2;239;15;0m₀.₀₁₁₅₃\u001b[0m alcoholic\u001b[0m \u001b[38;2;122;132;0m₀.₀₉₈₉₂\u001b[0m woman\u001b[0m \u001b[38;2;212;42;0m₀.₀₃₂₀₉\u001b[0m complains\u001b[0m \u001b[38;2;189;65;0m₀.₀₄₉₀₃\u001b[0m of\u001b[0m \u001b[38;2;236;18;0m₀.₀₁₃₄₇\u001b[0m chronic\u001b[0m \u001b[38;2;232;22;0m₀.₀₁₇₀₇\u001b[0m \u001b[45mliver\u001b[0m \u001b[38;2;0;255;0m₀.₁₉₀₅₇\u001b[0m pain\u001b[0m \u001b[38;2;129;125;0m₀.₀₉₃₈₈\u001b[0m and\u001b[0m \u001b[38;2;222;32;0m₀.₀₂₄₁₇\u001b[0m fatigue\u001b[0m \u001b[38;2;119;135;0m₀.₁₀₁₁₂\u001b[0m .\u001b[0m \u001b[38;2;215;39;0m₀.₀₂₉₂₃\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mAlcoholic hepatitis\u001b[0m \u001b[38;2;0;255;0m₀.₀₉₈₆₀\u001b[0m Diabetes \u001b[0m \u001b[38;2;50;204;0m₀.₀₇₉₀₅\u001b[0m Peptic ulcer diseae\u001b[0m \u001b[38;2;114;140;0m₀.₀₅₄₅₁\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;230;24;0m₀.₀₁₁₃₉\u001b[0m 32\u001b[0m \u001b[38;2;172;82;0m₀.₀₃₇₆₅\u001b[0m -\u001b[0m \u001b[38;2;243;11;0m₀.₀₀₅₃₈\u001b[0m year\u001b[0m \u001b[38;2;230;24;0m₀.₀₁₁₀₈\u001b[0m -\u001b[0m \u001b[38;2;250;4;0m₀.₀₀₂₀₉\u001b[0m old\u001b[0m \u001b[38;2;247;7;0m₀.₀₀₃₃₉\u001b[0m drug\u001b[0m \u001b[38;2;75;179;0m₀.₀₈₂₀₇\u001b[0m addict\u001b[0m \u001b[38;2;75;179;0m₀.₀₈₁₇₇\u001b[0m presents\u001b[0m \u001b[38;2;161;93;0m₀.₀₄₂₈₂\u001b[0m with\u001b[0m \u001b[38;2;235;19;0m₀.₀₀₉₁₁\u001b[0m shortness\u001b[0m \u001b[38;2;124;130;0m₀.₀₅₉₄₇\u001b[0m of\u001b[0m \u001b[38;2;210;44;0m₀.₀₂₀₃₈\u001b[0m breath\u001b[0m \u001b[38;2;75;179;0m₀.₀₈₁₇₉\u001b[0m and\u001b[0m \u001b[38;2;225;29;0m₀.₀₁₃₅₄\u001b[0m severe\u001b[0m \u001b[38;2;185;69;0m₀.₀₃₁₆₆\u001b[0m \u001b[45mcough\u001b[0m \u001b[38;2;0;255;0m₀.₁₁₆₄₆\u001b[0m .\u001b[0m \u001b[38;2;195;59;0m₀.₀₂₇₂₀\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mAcne\u001b[0m \u001b[38;2;0;255;0m₀.₀₆₇₈₆\u001b[0m Urinary tract infection\u001b[0m \u001b[38;2;10;244;0m₀.₀₆₅₂₀\u001b[0m Heart attack\u001b[0m \u001b[38;2;19;235;0m₀.₀₆₂₆₁\u001b[0m \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in remove_prejorative_sentences[:3]:\n",
        "  visualize_attention_and_predictions(sent, model, tokenizer, label_encoder, layer_num=-1, head_num=-1)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK9_1Cpy0F6C",
        "outputId": "1093c2c3-18ed-4103-9979-56761dae9873"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;214;40;0m₀.₀₁₁₈₇\u001b[0m 45\u001b[0m \u001b[38;2;139;115;0m₀.₀₃₃₆₃\u001b[0m -\u001b[0m \u001b[38;2;234;20;0m₀.₀₀₅₉₁\u001b[0m year\u001b[0m \u001b[38;2;224;30;0m₀.₀₀₉₀₀\u001b[0m -\u001b[0m \u001b[38;2;246;8;0m₀.₀₀₂₄₄\u001b[0m old\u001b[0m \u001b[38;2;240;14;0m₀.₀₀₄₁₆\u001b[0m man\u001b[0m \u001b[38;2;148;106;0m₀.₀₃₁₂₂\u001b[0m presents\u001b[0m \u001b[38;2;122;132;0m₀.₀₃₈₇₃\u001b[0m with\u001b[0m \u001b[38;2;218;36;0m₀.₀₁₀₇₄\u001b[0m severe\u001b[0m \u001b[38;2;144;110;0m₀.₀₃₂₁₇\u001b[0m chest\u001b[0m \u001b[38;2;41;213;0m₀.₀₆₂₃₇\u001b[0m \u001b[45mpain\u001b[0m \u001b[38;2;0;255;0m₀.₀₇₄₄₂\u001b[0m and\u001b[0m \u001b[38;2;189;65;0m₀.₀₁₉₀₀\u001b[0m nausea\u001b[0m \u001b[38;2;119;135;0m₀.₀₃₉₄₈\u001b[0m .\u001b[0m \u001b[38;2;103;151;0m₀.₀₄₄₂₈\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₂₁₄₀₆\u001b[0m Hypertension \u001b[0m \u001b[38;2;181;73;0m₀.₀₆₁₂₉\u001b[0m Malaria\u001b[0m \u001b[38;2;182;72;0m₀.₀₆₀₅₅\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "An\u001b[0m \u001b[38;2;208;46;0m₀.₀₄₃₂₄\u001b[0m woman\u001b[0m \u001b[38;2;142;112;0m₀.₁₀₅₃₀\u001b[0m complains\u001b[0m \u001b[38;2;200;54;0m₀.₀₅₀₈₅\u001b[0m of\u001b[0m \u001b[38;2;240;14;0m₀.₀₁₃₂₉\u001b[0m chronic\u001b[0m \u001b[38;2;234;20;0m₀.₀₁₈₇₆\u001b[0m \u001b[45mliver\u001b[0m \u001b[38;2;0;255;0m₀.₂₃₇₉₁\u001b[0m pain\u001b[0m \u001b[38;2;161;93;0m₀.₀₈₆₈₂\u001b[0m and\u001b[0m \u001b[38;2;221;33;0m₀.₀₃₁₃₂\u001b[0m fatigue\u001b[0m \u001b[38;2;129;125;0m₀.₁₁₆₆₉\u001b[0m .\u001b[0m \u001b[38;2;209;45;0m₀.₀₄₂₂₁\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mGastroenteritis\u001b[0m \u001b[38;2;0;255;0m₀.₀₇₀₆₉\u001b[0m Alcoholic hepatitis\u001b[0m \u001b[38;2;17;237;0m₀.₀₆₅₇₀\u001b[0m Peptic ulcer diseae\u001b[0m \u001b[38;2;52;202;0m₀.₀₅₆₁₉\u001b[0m \n",
            "\n",
            "\u001b[1mInput Words:\u001b[0m\n",
            "A\u001b[0m \u001b[38;2;229;25;0m₀.₀₁₃₁₇\u001b[0m 32\u001b[0m \u001b[38;2;190;64;0m₀.₀₃₃₃₁\u001b[0m -\u001b[0m \u001b[38;2;241;13;0m₀.₀₀₆₈₉\u001b[0m year\u001b[0m \u001b[38;2;226;28;0m₀.₀₁₄₄₉\u001b[0m -\u001b[0m \u001b[38;2;248;6;0m₀.₀₀₃₁₆\u001b[0m old\u001b[0m \u001b[38;2;245;9;0m₀.₀₀₅₀₂\u001b[0m presents\u001b[0m \u001b[38;2;179;75;0m₀.₀₃₈₆₀\u001b[0m with\u001b[0m \u001b[38;2;235;19;0m₀.₀₀₉₈₁\u001b[0m shortness\u001b[0m \u001b[38;2;98;156;0m₀.₀₈₀₅₁\u001b[0m of\u001b[0m \u001b[38;2;201;53;0m₀.₀₂₇₅₂\u001b[0m breath\u001b[0m \u001b[38;2;44;210;0m₀.₁₀₈₁₉\u001b[0m and\u001b[0m \u001b[38;2;219;35;0m₀.₀₁₈₀₇\u001b[0m severe\u001b[0m \u001b[38;2;172;82;0m₀.₀₄₂₁₂\u001b[0m \u001b[45mcough\u001b[0m \u001b[38;2;0;255;0m₀.₁₃₀₉₅\u001b[0m .\u001b[0m \u001b[38;2;174;80;0m₀.₀₄₁₁₇\u001b[0m \n",
            "\n",
            "\u001b[1mTop Predictions:\u001b[0m\n",
            "\u001b[45mHeart attack\u001b[0m \u001b[38;2;0;255;0m₀.₁₀₄₉₃\u001b[0m Urinary tract infection\u001b[0m \u001b[38;2;90;164;0m₀.₀₆₇₅₇\u001b[0m Hypertension \u001b[0m \u001b[38;2;105;149;0m₀.₀₆₁₅₂\u001b[0m \n",
            "\n"
          ]
        }
      ]
    }
  ]
}